{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Lambda School Data Science — Practicing & Understanding Predictive Modeling_\n",
    "\n",
    "# Model Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Links\n",
    "- [Kaggle / Dan Becker: Machine Learning Explainability](https://www.kaggle.com/learn/machine-learning-explainability)\n",
    "  - [Permutation Importance](https://www.kaggle.com/dansbecker/permutation-importance)\n",
    "  - [Partial Dependence Plots](https://www.kaggle.com/dansbecker/partial-plots)\n",
    "  - [Shapley Values](https://www.kaggle.com/dansbecker/shap-values)\n",
    "- [Christoph Molnar: Interpretable Machine Learning](https://christophm.github.io/interpretable-ml-book/)\n",
    "  - [(Permutation) Importance](https://christophm.github.io/interpretable-ml-book/feature-importance.html)\n",
    "  - [Partial Dependence Plots](https://christophm.github.io/interpretable-ml-book/pdp.html) + [animated explanation](https://twitter.com/ChristophMolnar/status/1066398522608635904)\n",
    "  - [Shapley Values](https://christophm.github.io/interpretable-ml-book/shapley.html)\n",
    "- Random Forest Feature Importances\n",
    "  - [Ando Saabas: Selecting good features, Part 3, Random Forests](https://blog.datadive.net/selecting-good-features-part-iii-random-forests/)\n",
    "  - [Terence Parr, et al: Beware Default Random Forest Importances](https://explained.ai/rf-importance/index.html)\n",
    "\n",
    "### Libraries\n",
    "- [eli5](https://github.com/TeamHG-Memex/eli5): `conda install -c conda-forge eli5` / `pip install eli5`\n",
    "- [PDPbox](https://github.com/SauceCat/PDPbox): `pip install pdpbox`\n",
    "- [shap](https://github.com/slundberg/shap): `conda install -c conda-forge shap` / `pip install shap`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library quirks to work around\n",
    "\n",
    "1. Some of these libraries don't work with pipelines.\n",
    "\n",
    "2. eli5 PermutationImportance + xgboost + pandas doesn't work, but [there's a work-around:](https://www.kaggle.com/dansbecker/permutation-importance#392299)\n",
    "\n",
    "> Important note here for anyone trying to use eli5's PermutationImportance on XGBoost estimators, currently you need to train your models using \".values or .as_matrix()\" with you input data (X and Y), otherwise PermutationImportance won't work, [source](https://github.com/TeamHG-Memex/eli5/issues/256).\n",
    "\n",
    "3. PDPbox _only_ works with pandas.\n",
    "\n",
    "***[Data science is often about putting square pegs in round holes!](https://www.youtube.com/watch?v=ry55--J4_VQ)***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 types of model explanations today!\n",
    "\n",
    "#### Global explanation: all features in relation to each other\n",
    "- Feature Importances: _Default, fastest, good for first estimates_\n",
    "- Drop-Column Importances: _The best in theory, but much too slow in practice_\n",
    "- Permutaton Importances: _A good compromise!_\n",
    "\n",
    "#### Global explanation: individual feature(s) in relation to target\n",
    "- Partial Dependence plots\n",
    "\n",
    "#### Individual prediction explanation\n",
    "- Shapley Values\n",
    "\n",
    "_Note that the coefficients from a linear model give you all three types of explanations!_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture dataset: Lending Club\n",
    "\n",
    "#### Can you predict if peer-to-peer loans are charged off or fully paid?\n",
    "\n",
    "[Lending Club says,](https://www.lendingclub.com/) _\"Our mission is to transform the banking system to make credit more affordable and investing more rewarding.\"_ You can view their [loan statistics and visualizations](https://www.lendingclub.com/info/demand-and-credit-profile.action).\n",
    "\n",
    "[According to Wikipedia,](https://en.wikipedia.org/wiki/Lending_Club)\n",
    "\n",
    "> Lending Club is the world's largest peer-to-peer lending platform. Lending Club enables borrowers to create unsecured personal loans between $1,000 and 40,000. The standard loan period is three years. Investors can search and browse the loan listings on Lending Club website and select loans that they want to invest in based on the information supplied about the borrower, amount of loan, loan grade, and loan purpose. Investors make money from interest. Lending Club makes money by charging borrowers an origination fee and investors a service fee.\n",
    "\n",
    "The data is a stratified sample of 100,000 Lending Club peer-to-peer loans with a loan status of \"Charged Off\" or \"Fully Paid\", issued from 2007 through 2018.\n",
    "\n",
    "The set of variables included here are the intersection of what's available both when investors download historical data and when investors browse loans for manual investing.\n",
    "\n",
    "Data dictionary: https://resources.lendingclub.com/LCDataDictionary.xlsx\n",
    "\n",
    "Target: `charged_off`\n",
    "\n",
    "**This is a classification problem, so we'll choose a [scoring metric](https://scikit-learn.org/stable/modules/model_evaluation.html#common-cases-predefined-values) for classification: ROC AUC.**\n",
    "\n",
    "**For our evaluation protocol, we'll choose cross-validation with independent test set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.options.display.max_columns = 500\n",
    "pd.options.display.max_rows = 500\n",
    "\n",
    "\n",
    "url = 'https://drive.google.com/uc?export=download&id=1AafT_i1dmfaxqKiyFofVndleKozbQw3l'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "X = df.drop(columns='charged_off')\n",
    "y = df['charged_off']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, train_size=0.80, test_size=0.20, stratify=y, random_state=42)\n",
    "\n",
    "\n",
    "def wrangle(X):\n",
    "    X = X.copy()\n",
    "    \n",
    "    # Drop some columns\n",
    "    X = X.drop(columns='id')  # id is random\n",
    "    X = X.drop(columns=['member_id', 'url', 'desc'])  # All null\n",
    "    X = X.drop(columns='title')  # Duplicative of purpose\n",
    "    X = X.drop(columns='grade')  # Duplicative of sub_grade\n",
    "    \n",
    "    # Transform sub_grade from \"A1\" - \"G5\" to 1.1 - 7.5\n",
    "    def wrangle_sub_grade(x):\n",
    "        first_digit = ord(x[0]) - 64\n",
    "        second_digit = int(x[1])\n",
    "        return first_digit + second_digit/10\n",
    "    \n",
    "    X['sub_grade'] = X['sub_grade'].apply(wrangle_sub_grade)\n",
    "\n",
    "    # Convert percentages from strings to floats\n",
    "    X['int_rate'] = X['int_rate'].str.strip('%').astype(float)\n",
    "    X['revol_util'] = X['revol_util'].str.strip('%').astype(float)\n",
    "        \n",
    "    # Transform earliest_cr_line to an integer: how many days it's been open\n",
    "    X['earliest_cr_line'] = pd.to_datetime(X['earliest_cr_line'], infer_datetime_format=True)\n",
    "    X['earliest_cr_line'] = pd.Timestamp.today() - X['earliest_cr_line']\n",
    "    X['earliest_cr_line'] = X['earliest_cr_line'].dt.days\n",
    "    \n",
    "    # Create features for three employee titles: teacher, manager, owner\n",
    "    X['emp_title'] = X['emp_title'].str.lower()\n",
    "    X['emp_title_teacher'] = X['emp_title'].str.contains('teacher', na=False)\n",
    "    X['emp_title_manager'] = X['emp_title'].str.contains('manager', na=False)\n",
    "    X['emp_title_owner']   = X['emp_title'].str.contains('owner', na=False)\n",
    "    \n",
    "    # Drop categoricals with high cardinality\n",
    "    X = X.drop(columns=['emp_title', 'zip_code'])\n",
    "    \n",
    "    # Transform features with many nulls to binary flags\n",
    "    many_nulls = ['sec_app_mths_since_last_major_derog',\n",
    "                  'sec_app_revol_util',\n",
    "                  'sec_app_earliest_cr_line',\n",
    "                  'sec_app_mort_acc',\n",
    "                  'dti_joint',\n",
    "                  'sec_app_collections_12_mths_ex_med',\n",
    "                  'sec_app_chargeoff_within_12_mths',\n",
    "                  'sec_app_num_rev_accts',\n",
    "                  'sec_app_open_act_il',\n",
    "                  'sec_app_open_acc',\n",
    "                  'revol_bal_joint',\n",
    "                  'annual_inc_joint',\n",
    "                  'sec_app_inq_last_6mths',\n",
    "                  'mths_since_last_record',\n",
    "                  'mths_since_recent_bc_dlq',\n",
    "                  'mths_since_last_major_derog',\n",
    "                  'mths_since_recent_revol_delinq',\n",
    "                  'mths_since_last_delinq',\n",
    "                  'il_util',\n",
    "                  'emp_length',\n",
    "                  'mths_since_recent_inq',\n",
    "                  'mo_sin_old_il_acct',\n",
    "                  'mths_since_rcnt_il',\n",
    "                  'num_tl_120dpd_2m',\n",
    "                  'bc_util',\n",
    "                  'percent_bc_gt_75',\n",
    "                  'bc_open_to_buy',\n",
    "                  'mths_since_recent_bc']\n",
    "\n",
    "    for col in many_nulls:\n",
    "        X[col] = X[col].isnull()\n",
    "    \n",
    "    # For features with few nulls, do mean imputation\n",
    "    for col in X:\n",
    "        if X[col].isnull().sum() > 0:\n",
    "            X[col] = X[col].fillna(X[col].mean())\n",
    "    \n",
    "    # Return the wrangled dataframe\n",
    "    return X\n",
    "\n",
    "\n",
    "# Wrangle train and test in the same way\n",
    "X_train = wrangle(X_train)\n",
    "X_test  = wrangle(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce\n",
    "from scipy.stats import randint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "encoder = ce.OrdinalEncoder()\n",
    "X_train = encoder.fit_transform(X_train)\n",
    "\n",
    "param_distributions = {\n",
    "    'n_estimators': randint(50, 300), \n",
    "    'max_depth': randint(2, 4)\n",
    "}\n",
    "\n",
    "# n_iter & cv parameters are low here so the example runs faster\n",
    "search = RandomizedSearchCV(\n",
    "    estimator=XGBClassifier(n_jobs=-1, random_state=42), \n",
    "    param_distributions=param_distributions, \n",
    "    n_iter=2, \n",
    "    scoring='roc_auc', \n",
    "    n_jobs=-1, \n",
    "    cv=2, \n",
    "    verbose=10, \n",
    "    return_train_score=True, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "search.fit(X_train.values, y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Cross-Validation ROC AUC:', search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "best = search.best_estimator_\n",
    "X_test = encoder.transform(X_test)\n",
    "y_pred_proba = best.predict_proba(X_test.values)[:,1]\n",
    "print('Test ROC AUC:', roc_auc_score(y_test, y_pred_proba))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1a. Feature Importances\n",
    "- Global explanation: all features in relation to each other\n",
    "- Default, fastest, good for first estimates\n",
    "\n",
    "[Here's some food for thought](https://blog.datadive.net/selecting-good-features-part-iii-random-forests/) about feature importances:\n",
    "\n",
    ">**When the dataset has two (or more) correlated features, then from the point of view of the model, any of these correlated features can be used as the predictor, with no concrete preference of one over the others.** But once one of them is used, the importance of others is significantly reduced since effectively the impurity they can remove is already removed by the first feature. As a consequence, they will have a lower reported importance. This is not an issue when we want to use feature selection to reduce overfitting, since it makes sense to remove features that are mostly duplicated by other features. But when interpreting the data, it can lead to the incorrect conclusion that one of the variables is a strong predictor while the others in the same group are unimportant, while actually they are very close in terms of their relationship with the response variable.\n",
    "\n",
    "For more information, see [Beware Default Random Forest Importances](https://explained.ai/rf-importance/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1b. Drop-Column Importance\n",
    "- Global explanation: all features in relation to each other\n",
    "- The best in theory, but much too slow in practice\n",
    "\n",
    "`sub_grade` is correlated with `int_rate`. If we drop `sub_grade`, the model uses other correlated features more, so the score remains similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "X_train_no_subgrade = X_train.drop(columns='sub_grade')\n",
    "new_model = XGBClassifier(max_depth=2, n_estimators=200, n_jobs=-1, random_state=42)\n",
    "\n",
    "score_with = cross_val_score(new_model, X_train, y_train, cv=2, scoring='roc_auc').mean()\n",
    "print('Cross-Validation ROC AUC with sub_grade:', score_with)\n",
    "\n",
    "score_without = cross_val_score(new_model, X_train_no_subgrade, y_train, cv=2, scoring='roc_auc').mean()\n",
    "print('Cross-Validation ROC AUC without sub_grade:', score_without)\n",
    "\n",
    "print('Drop-Column Importance:', score_with - score_without)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1c. Permutation Importance\n",
    "- Global explanation: all features in relation to each other\n",
    "- A good compromise!\n",
    "\n",
    "Permutation Importance is a compromise between Feature Importance based on impurity reduction (which is the fastest) and Drop Column Importance (which is the \"best.\")\n",
    "\n",
    "[The ELI5 library documentation explains,](https://eli5.readthedocs.io/en/latest/blackbox/permutation_importance.html)\n",
    "\n",
    "> Importance can be measured by looking at how much the score (accuracy, F1, R^2, etc. - any score we’re interested in) decreases when a feature is not available.\n",
    ">\n",
    "> To do that one can remove feature from the dataset, re-train the estimator and check the score. But it requires re-training an estimator for each feature, which can be computationally intensive. ...\n",
    ">\n",
    ">To avoid re-training the estimator we can remove a feature only from the test part of the dataset, and compute score without using this feature. It doesn’t work as-is, because estimators expect feature to be present. So instead of removing a feature we can replace it with random noise - feature column is still there, but it no longer contains useful information. This method works if noise is drawn from the same distribution as original feature values (as otherwise estimator may fail). The simplest way to get such noise is to shuffle values for a feature, i.e. use other examples’ feature values - this is how permutation importance is computed.\n",
    ">\n",
    ">The method is most suitable for computing feature importances when a number of columns (features) is not huge; it can be resource-intensive otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do-It-Yourself way, for intuition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With eli5 library\n",
    "\n",
    "For more documentation on using this library, see:\n",
    "- [eli5.sklearn.PermutationImportance](https://eli5.readthedocs.io/en/latest/autodocs/sklearn.html#eli5.sklearn.permutation_importance.PermutationImportance)\n",
    "- [eli5.show_weights](https://eli5.readthedocs.io/en/latest/autodocs/eli5.html#eli5.show_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can use importances for feature selection\n",
    "\n",
    "For example, we can remove features with zero importance. The model trains faster and the score does not decrease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refit the model after we remove features with zero importance\n",
    "\n",
    "param_distributions = {\n",
    "    'n_estimators': randint(50, 300), \n",
    "    'max_depth': randint(2, 4)\n",
    "}\n",
    "\n",
    "# n_iter & cv parameters are low here so the example runs faster\n",
    "search = RandomizedSearchCV(\n",
    "    estimator=XGBClassifier(n_jobs=-1, random_state=42), \n",
    "    param_distributions=param_distributions, \n",
    "    n_iter=2, \n",
    "    scoring='roc_auc', \n",
    "    n_jobs=-1, \n",
    "    cv=2, \n",
    "    verbose=10, \n",
    "    return_train_score=True, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Cross-Validation ROC AUC:', search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = search.best_estimator_\n",
    "X_test = X_test[features]\n",
    "y_pred_proba = best.predict_proba(X_test)[:,1]\n",
    "print('Test ROC AUC:', roc_auc_score(y_test, y_pred_proba))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Partial Dependence Plots\n",
    "\n",
    "PDPbox\n",
    "- [Gallery](https://github.com/SauceCat/PDPbox#gallery)\n",
    "- [API Reference: pdpbox.pdp.pdp_isolate](https://pdpbox.readthedocs.io/en/latest/pdp_isolate.html)\n",
    "- [API Reference: pdpbox.pdp.pdp_plot](https://pdpbox.readthedocs.io/en/latest/pdp_plot.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explaining Partial Dependence Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From [PDPbox documentation](https://pdpbox.readthedocs.io/en/latest/):\n",
    "\n",
    "\n",
    ">**The common headache**: When using black box machine learning algorithms like random forest and boosting, it is hard to understand the relations between predictors and model outcome. For example, in terms of random forest, all we get is the feature importance. Although we can know which feature is significantly influencing the outcome based on the importance calculation, it really sucks that we don’t know in which direction it is influencing. And in most of the real cases, the effect is non-monotonic. We need some powerful tools to help understanding the complex relations between predictors and model prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Animation by Christoph Molnar](https://twitter.com/ChristophMolnar/status/1066398522608635904), author of [_Interpretable Machine Learning_](https://christophm.github.io/interpretable-ml-book/)\n",
    "\n",
    "> Partial dependence plots show how a feature affects predictions of a Machine Learning model on average.\n",
    "> 1. Define grid along feature\n",
    "> 2. Model predictions at grid points\n",
    "> 3. Line per data instance -> ICE (Individual Conditional Expectation) curve\n",
    "> 4. Average curves to get a PDP (Partial Dependence Plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partial Dependence Plots with 2 features, to see interactions\n",
    "\n",
    "PDPbox\n",
    "- [Gallery](https://github.com/SauceCat/PDPbox#gallery)\n",
    "- [API Reference: pdpbox.pdp.pdp_interact](https://pdpbox.readthedocs.io/en/latest/pdp_interact.html)\n",
    "- [API Reference: pdpbox.pdp.pdp_interact_plot](https://pdpbox.readthedocs.io/en/latest/pdp_interact_plot.html)\n",
    "\n",
    "Be aware of a bug in PDPBox version <= 0.20:\n",
    "- With the `pdp_interact_plot` function, `plot_type='contour` gets an error, but `plot_type='grid'` works\n",
    "- This will be fixed in the next release of PDPbox: https://github.com/SauceCat/PDPbox/issues/40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Shapley Values to explain individual predictions\n",
    "\n",
    "[Dan Becker explains,](https://www.kaggle.com/dansbecker/shap-values)\n",
    "\n",
    ">You've seen (and used) techniques to extract general insights from a machine learning model. But what if you want to break down how the model works for an individual prediction?\n",
    "\n",
    ">SHAP Values (an acronym from SHapley Additive exPlanations) break down a prediction to show the impact of each feature. \n",
    "\n",
    ">There is some complexity to the technique ... We won't go into that detail here, since it isn't critical for using the technique. [This blog post](https://towardsdatascience.com/one-feature-attribution-method-to-supposedly-rule-them-all-shapley-values-f3e04534983d) has a longer theoretical explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (y_pred_proba >= 0.5).astype(int)\n",
    "confidence = np.abs(y_pred_proba - 0.5)\n",
    "preds = pd.DataFrame({'y_test': y_test, 'y_pred': y_pred, \n",
    "                      'y_pred_proba': y_pred_proba, \n",
    "                      'confidence': confidence})\n",
    "\n",
    "preds.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### True positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### True negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### False positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### False negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASSIGNMENT\n",
    "\n",
    "In a clean notebook, using the **Seattle Bicycle Weather** dataset, make these visualizations:\n",
    "\n",
    "- Feature Importances\n",
    "- Permutation Importances\n",
    "- Partial Dependence Plot\n",
    "- Shapley Values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
